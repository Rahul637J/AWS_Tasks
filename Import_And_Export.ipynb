{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'''<br>\n",
    "@Author: Rahul<br> \n",
    "@Date: 2024-10-24<br>\n",
    "@Last Modified by: Rahul <br>\n",
    "@Last Modified time: 2024-10-24<br>\n",
    "@Title: Python program to Import and Export data Using Boto3<br>\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import from Database and Export to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymssql\n",
    "import csv\n",
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to order_data.csv\n",
      "File uploaded to S3: rahulbllamdabucket/order_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def connect_to_database(endpoint, port, username, password, database):\n",
    "    conn = pymssql.connect(server=f\"{endpoint}:{port}\", user=username, password=password, database=database)\n",
    "    return conn\n",
    "\n",
    "def export_data_to_csv(conn, table_name, csv_file):\n",
    "    cursor = conn.cursor()\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([i[0] for i in cursor.description])  # Write headers\n",
    "        writer.writerows(cursor.fetchall())  # Write data\n",
    "    \n",
    "    print(f\"Data exported to {csv_file}\")\n",
    "\n",
    "def upload_file_to_s3(file_name, bucket_name, s3_file_name):\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    try:\n",
    "        s3.upload_file(file_name, bucket_name, s3_file_name)\n",
    "        print(f\"File uploaded to S3: {bucket_name}/{s3_file_name}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"The file was not found.\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"AWS credentials not available.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    server = 'rahulbldb-rj.cxsygi2uk94v.ap-south-1.rds.amazonaws.com'\n",
    "    port = 1433  \n",
    "    database = 'rdsrahul'\n",
    "    username = 'admin'\n",
    "    password = 'RaHuL637j'\n",
    "\n",
    "    bucket_name = 'rahulbllamdabucket'\n",
    "    file_name = 'order_data.csv'\n",
    "    local_file_path = 'order_data.csv'\n",
    "\n",
    "    table_name = \"Orders\"\n",
    "\n",
    "    conn = connect_to_database(server, port, username, password, database)\n",
    "    try:\n",
    "        export_data_to_csv(conn, table_name, local_file_path)\n",
    "        \n",
    "        upload_file_to_s3(local_file_path, bucket_name, file_name)\n",
    "    finally:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection successful!\n",
      "File downloaded from S3: rahulbllamdabucket/exported_data.csv to imported_data.csv\n",
      "Data imported from imported_data.csv to Orders\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def connect_to_database(endpoint, port, username, password, database):\n",
    "    try:\n",
    "        conn = pymssql.connect(server=f\"{endpoint}:{port}\", user=username, password=password, database=database)\n",
    "        print(\"Database connection successful!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to database: {e}\")\n",
    "        return None\n",
    "\n",
    "def download_file_from_s3(bucket_name, s3_file_name, local_file_name):\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    try:\n",
    "        s3.download_file(bucket_name, s3_file_name, local_file_name)\n",
    "        print(f\"File downloaded from S3: {bucket_name}/{s3_file_name} to {local_file_name}\")\n",
    "    except NoCredentialsError:\n",
    "        print(\"AWS credentials not available.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file from S3: {e}\")\n",
    "\n",
    "def import_data_from_csv(conn, table_name, csv_file, identity_column):\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    if identity_column in df.columns:\n",
    "        df = df.drop(columns=[identity_column])\n",
    "\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting column '{col}': {e}\")\n",
    "\n",
    "    \n",
    "    df.dropna(inplace=True)  \n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        placeholders = ', '.join(['%s'] * len(row)) \n",
    "        insert_query = f\"INSERT INTO {table_name} ({', '.join(df.columns)}) VALUES ({placeholders})\"\n",
    "        cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\"Data imported from {csv_file} to {table_name}\")\n",
    "    cursor.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    server = 'rahulbldb-rj.cxsygi2uk94v.ap-south-1.rds.amazonaws.com'\n",
    "    port = 1433  \n",
    "    database = 'rdsrahul'\n",
    "    username = 'admin'\n",
    "    password = 'RaHuL637j'\n",
    "\n",
    " \n",
    "    bucket_name = 'rahulbllamdabucket'\n",
    "    s3_file_name = 'exported_data.csv'  \n",
    "    local_file_path = 'imported_data.csv'  \n",
    "\n",
    "    table_name = \"Orders\"\n",
    "    identity_column = 'OrderID'  \n",
    "\n",
    "    conn = connect_to_database(server, port, username, password, database)\n",
    "    if conn:\n",
    "        try:\n",
    "            download_file_from_s3(bucket_name, s3_file_name, local_file_path)\n",
    "\n",
    "            import_data_from_csv(conn, table_name, local_file_path, identity_column)\n",
    "        finally:\n",
    "            conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
